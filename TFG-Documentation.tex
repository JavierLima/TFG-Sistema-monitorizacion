%Preambulo
\documentclass[ spanish, a4paper, 12pt, oneside]{report}
\usepackage{hyphenat}
\usepackage{graphicx}

\graphicspath{ {TFGImages/} }
% Cuerpo
\title{\Huge MACHMON - Monitorización de sistemas }
\author{Javier Lima}
\date{Junio 2020}

\begin{document}

\begin{titlepage}
   \centering
   {\bfseries\LARGE U-tad \par}
   \vspace{1cm}
   {\scshape\Large Facultad de Ingeniería de software \par}
   \vspace{3cm}
   {\scshape\Huge MACHMON - Monitorización de sistemas \par}
   \vspace{3cm}
   {\itshape\Large Proyecto Fin de Carrera \par}
   \vfill
   {\Large Autor: \par}
   {\Large Javier Lima \par}
   \vfill
   {\Large Junio 2020 \par}
\end{titlepage}

\tableofcontents{}
\newpage

\chapter{Abstract}


This TFG covers a distributed system for monitoring systems (machines). The main objective of the project is to develop a distributed application for 
the collection of different states of distributed systems. A Server - Workers architecture is proposed, so that the Server runs on one machine, and the Workers 
run on the machines to be monitored. \\

The project also requires a communication protocol that has to be design between the different pairs of the application (Server and Workers), abstracting 
the peculiarities of each system to be monitored. Once the data has been collected, the Server cleans it, enriches it and stores it, so the "UI"(user interface), 
in this case Grafana, can use the stored data to display graphs of them. \\

Python is used as the main language, at the same time bash is used to collect the metrics and protobuffer for the communications protocol. As the main tool for 
managing the software life cycle, git and GitHub are used. \\

\chapter{Introducción}

\section{Justificación y contexto}


Actualmente, la monitorización de los ordenadores, es común en todas las empresas con sistemas propios que manejen datos de forma 
digital, es un paso más en el control de los sistemas, al final acabas aprovechando más los recursos, prevees posibles incidencias, mejoras la 
experiencia del cliente y ahorras tiempo y dinero. \\

Los recursos de los que dispones en un ordenador son muy amplios, el tener controlado en todo momento dichos recursos te permite tomar decisiones
con mucha más seguridad. Pongamos un ejemplo, imaginémonos un sistema donde corren distintas aplicaciones, ¿cómo sabríamos si es viable introducir otra 
aplicación dentro del sistema?, a priori no lo sabes, introducirías la aplicación dentro del sistema hasta que en algún momento deje de funcionar. 
En cambio, si desde un principio supiésemos la salud del sistema, cuanto porcentaje de cpu está gastando o cuanta memoria RAM queda libre para que trabajen
paralelamente, podríamos adelantarnos a posibles incidencias y no saturar los sistemas de recursos o por el contrario darnos cuenta que deberíamos 
aprovechar más los recursos del sistema.\\

Tener monitorizado tus propios sistemas aporta tranquilidad, es un plus que cualquier cliente se sentería satisfecho, no solo hay que conformarse con elaborar 
una aplicación y ponerla a funcionar, hay que dejar preparadas ayudas que nos aporten valor por si ocurre alguna incidencia. No es fácil arreglar posibles fallos
que pueda tener una aplicación, sobre todo porque es posible que ni si quiera sea fallo de la aplicación, ante eso hay que bajar un nivel y entender  
que está ocurriendo dentro del sistema.\\ 

\section{Planteamiento del problema}
Todo este tiempo en la universidad hemos desarrollado código para generar valor con aplicacones o scripts, pero ¿cómo medimos 
el rendimiento del sistema realmente?. Imaginemos que tenemos varias aplicaciones funcionando en una máquina, ¿como 
podríamos saber si es posible meter una nueva aplicación dentro del sistema?. Machmon, es un proyecto para profundizar en 
los sistemas y así poder saber la salud de ellos, consiste en recoger métricas que nos aporten información sobre la salud de los
ordenadores (como la cpu, memoria ram, disco, etc) y representarlas gráficamente para sacar conclusiones sobre sus estados. \\



\section{Objetivos del trabajo}
Como propósito este trabajo tendrá unos objetivos a cumplir:\\

\subsection{Aumentar mis conocientos de sistemas linux}
Linux es uno de los sistemas más populares entre los desarrolladores, la consola que tiene facilita mucho la operación de esas 
máquinas. Es por ello, que el uso de los sistemas Linux me va a ayudar al manejo de esos sistemas.\\

\subsection{Utilizar tecnologías nuevas}
La programación es muy revolucionaria, en cualquier momento aparece una aplicación nueva capaz de dejar obsoleta a otra. 
El estar puesto en las nuevas tecnologías nos facilita el trabajo, nos permite ver las utilidades de cada herramienta y los
beneficios que nos pueda aportar. \\

Este trabajo tiene un fin, obtener la salud de los sistemas monitorizados, pero en el camino nos encontremos dificultades que 
seguramente una herramienta nos las solucione. \\

\subsection{Modelo abstracto}
Es un objetivo un poco pretencioso, trata de ser capaz de recibir métricas de cualquier tipo de sistema, que exista una entidad
capaz de controlar los mensajes recibidos y almacenarlos para su tratamiento, es decir, que si en algún momento decido introducir 
una nueva máquina en el sistema sea capaz de entender los mensajes también y almacenarlos. \\

\subsection{Concurrencia}
Es un objetivo fundamental, es necesario tener en cuenta posibles mensajes que lleguen a la vez. La concurrencia nos soluciona el 
objetivo, tendremos que ser capaces de elaborar un sistema concurrente.\\

\chapter{Estado de la cuestión}












\chapter{Aspectos metodológicos}

\section{Metodología}

\section{Tecnologías empleadas}
En la actualidad hay multitud de herramientas, nos facilitan el trabajo si las conocemos y las utilizamos según el propósito de su existencia. 
Aunque se nombren muchas herramientas a continuación, existen muchas otras que también podían haber sido de utilidad, un ejemplo de ello es "Prometheus" 
que no se llega a utilizar en este trabajo, pero su función de recoger métricas se hubiese adaptado muy bien, además de que en el mundo laboral se utiliza con 
frecuencia.\\

A continuación se mostrarán todas las tecnologías utilizadas.\\

\subsection{Docker}
Un contenedor es una unidad de software estándar que empaqueta el código y todas sus dependencias para que la aplicación 
se ejecute de manera rápida y confiable de un entorno informático a otro. Una imagen de contenedor Docker es un paquete 
de software, independiente, gestionable y que incluye todo lo necesario para ejecutar una aplicación: código, tiempo 
de ejecución, herramientas del sistema, bibliotecas del sistema y configuraciones.\\

Las imágenes de dcoker se convierten en contenedores en tiempo de ejecución y, en el caso de los contenedores Docker, 
las imágenes se convierten en contenedores cuando se ejecutan en Docker Engine. Disponible para aplicaciones basadas en 
Linux y Windows, el software en contenedores siempre se ejecutará igual, independientemente de la infraestructura. Los 
contenedores aíslan el software de su entorno y aseguran que funcione de manera uniforme a pesar de las diferencias, por 
ejemplo, entre el desarrollo y la puesta en escena.\\

La tecnología de contenedores Docker se lanzó en 2013 como un motor Docker de código abierto. Aprovechó los conceptos 
informáticos existentes en torno a los contenedores y específicamente en el mundo de Linux, primitivas conocidas como 
cgroups y espacios de nombres. La tecnología de Docker es única porque se centra en los requisitos de los desarrolladores 
y operadores de sistemas para separar las dependencias de las aplicaciones de la infraestructura.
El éxito en el mundo de Linux impulsó una asociación con Microsoft que llevó los contenedores Docker y su funcionalidad 
a Windows Server.\\

\textbf{Comparación entre contenedores y máquinas virtuales}\\
Los contenedores y las máquinas virtuales tienen beneficios similares de aislamiento y asignación de recursos, pero 
funcionan de manera diferente porque los contenedores virtualizan el sistema operativo en lugar del hardware. 
Los contenedores son más portátiles y eficientes.\\

Los contenedores son una abstracción en la capa de la aplicación que agrupa el código y las dependencias juntas. 
Se pueden ejecutar varios contenedores en la misma máquina y compartir el núcleo del sistema operativo con otros 
contenedores, cada uno de los cuales se ejecuta como procesos aislados en el espacio del usuario. Los contenedores ocupan 
menos espacio que las máquinas virtuales (las imágenes de los contenedores suelen tener un tamaño de decenas de MB), 
pueden manejar más aplicaciones y requieren menos máquinas virtuales y sistemas operativos.\\

\begin{figure}[!h]
   \centering
   \includegraphics[width=0.6\textwidth]{container-application}\\
      \caption{\label{fig: container} Container}
\end{figure}


En cambio, las máquinas virtuales (VM) son una abstracción del hardware físico que convierte un servidor en muchos 
servidores. El hipervisor permite que varias máquinas virtuales se ejecuten en una sola máquina. Cada VM incluye una 
copia completa de un sistema operativo, la aplicación, los binarios y bibliotecas necesarias, que ocupan decenas de GB. 
Las máquinas virtuales también pueden ser lentas para arrancar.\\

\begin{figure}[!h]
   \centering
   \includegraphics[width=0.6\textwidth]{vm-application}\\
      \caption{\label{fig: vm} VM}
\end{figure}



\subsection{Protocol buffers}
Protobuffer diseñado internamente por Google, es una herramienta que nos permite generar protocolos de comunicaciones o estructuras de mensajes para facilitar al usuario las comunicaciones, a través de la serialización de mensajes.
La serialización es un proceso de codificación de un objeto en un medio de almacenamiento, como puede ser una archivo o un buffer en memoria, en ocasiones para transmitirlo a través de una conexión de red o para preservarlo entre ejecuciones 
de un programa. La serie de bytes que codifican el estado del objeto tras la serialización puede ser usada para crear un nuevo objeto, idéntico al original, tras aplicar el proceso inverso de deserialización. Además, dispone de un compilador que 
te permite una vez hecho el esquema de la estructura de datos codificarlo en distintos lenguajes; C++, Java, python, Objective-C y con la versión proto3 se puede trabajar con: Dart, Go, Ruby y C. \\ 

Según la página oficial de Google, los buffers de protocolo son el mecanismo extensible de lenguaje neutral, plataforma neutral para serializar datos estructurados; como en XML, pero más pequeño, más rápido y más simple. Uno define cómo desea que se 
organicen los datos una vez, luego puede usar un código fuente generado especial para escribir y leer fácilmente sus datos estructurados hacia y desde una variedad de flujos de datos y usando una variedad de idiomas. \\

\begin{figure}[!h]
   \centering
   \includegraphics[width=0.8\textwidth]{Protobuffer-example}\\
      \caption{\label{fig: Protobuffer example} Ejemplo Protobuffer}
\end{figure}

\subsection{Grafana}
El proyecto Grafana fue iniciado por Torkel Ödegaard en 2014 y en los últimos años se ha convertido en uno de los proyectos de código abierto más populares en GitHub. Le permite consultar, visualizar y alertar sobre métricas y registros sin importar 
dónde estén almacenados. \\

Grafana tiene un modelo de fuente de datos conectable y viene con un amplio soporte para muchas de las bases de datos de series de tiempo más populares como Graphite, Prometheus, Elasticsearch, OpenTSDB e InfluxDB. También tiene soporte incorporado 
para proveedores de monitoreo en la nube como Google Stackdriver, Amazon Cloudwatch, Microsoft Azure y bases de datos SQL como MySQL y Postgres. Grafana es la única herramienta que puede combinar datos de tantos lugares en un solo tablero. \\

\begin{figure}[!h]
   \centering
   \includegraphics[width=0.8\textwidth]{Grafana-login}\\
      \caption{\label{fig: Login Grafana} Login Grafana}
\end{figure}

Grafana Labs se enorgullece de liderar el desarrollo del proyecto Grafana, fomentando una comunidad próspera y asegurando que los clientes de Grafana Labs reciban el soporte y las características de Grafana que necesitan. \\

\subsection{InfluxDB}
InfluxDB es una base de datos de series temporales desarrollada por InfluxData. Está escrito en Go y optimizado para el almacenamiento rápido, la alta disponibilidad y la recuperación de datos de series de tiempo en campos como 
monitoreo de operaciones, métricas de aplicaciones, datos de sensores de Internet de las cosas y análisis en tiempo real. También tiene soporte para procesar datos y ser capaz de hacer agrupaciones, reducciones, añadir campos tras realizar cálculos, para resumir es capaz de 
hacer transformaciones sobre los datos obtenidos de las métricas a tiempo real. \\

\begin{figure}[!h]
   \centering
   \includegraphics[width=0.8\textwidth]{logo-influxdb}\\
      \caption{\label{fig: Logo InfluxDB} Logo InfluxDB}
\end{figure}

InfluxDB no tiene dependencias externas y proporciona un lenguaje similar a SQL, escuchando en el puerto 8086, con funciones centradas en el tiempo, incorporadas para consultar una estructura de datos compuesta de medidas, series y puntos. Cada punto consta de varios 
pares clave-valor, por un lado el conjunto de campos y por el otro una marca de tiempo (un timestamp). Cuando se agrupan por un conjunto de pares clave-valor llamado conjunto de etiquetas, definen una serie. Finalmente, las series se agrupan por un identificador de cadena para 
formar una medida. Dicha medida es el jugo de la aplicación, gracias a esas medidas obtenidas a tiempo real podríamos hacer estudios sobre ellas y sacarle el máximo potencial. \\

Los valores pueden ser enteros de 64 bits, puntos flotantes de 64 bits, cadenas y booleanos. Los puntos se indexan por su tiempo y conjunto de etiquetas. Las políticas de retención se definen en una medición y controlan cómo se 
disminuyen y eliminan los datos. Por último, las consultas continuas se ejecutan periódicamente, almacenando los resultados en una medición objetivo. \\

Según Capital One, un holding bancario de Estados Unidos, InfluxDB es una base de datos de lectura y escritura de alta velocidad. Los datos se escriben en tiempo real, puede leer en tiempo real, y cuando lo está leyendo, se puede aplicar su modelo de aprendizaje automático. 
Entonces, en tiempo real, se puede pronosticar y detectar anomalías. \\


\subsection{PyCharm}
Es un IDE de python desarrollado por programadores y para programadores creado por Jet Brains, una herramienta que te facilita programar a través de: finalización de código inteligente, detección de errores de código sobre la marcha y posibles arreglos, navegación simple en proyectos, 
integración continua con Git y mucho más. \\

\begin{figure}[!h]
   \centering
   \includegraphics[width=0.3\textwidth]{logo-pycharm}\\
      \caption{\label{fig: Logo Pycharm} Logo Pycharm}
\end{figure}

\subsection{Python}
Python es un lenguaje de programación interpretado cuya filosofía hace hincapié en la legibilidad de su código. Creado por Guido van Rossum y lanzado por primera vez en 1991, sus construcciones de lenguaje y su enfoque orientado a objetos tienen como objetivo ayudar a los 
programadores a escribir código claro y lógico para proyectos a pequeña y gran escala. Admite múltiples paradigmas de programación , incluida la programación estructurada, orientada a objetos y funcional. \\

\begin{figure}[!h]
   \centering
   \includegraphics[width=0.3\textwidth]{Python-logo}\\
      \caption{\label{fig: Logo Python} Logo Python}
\end{figure}

Es administrado por la Python Software Foundation y posee una licencia de código abierto, denominada Python Software Foundation License.\\
\subsection{Ubuntu}

Ubuntu es un sistema operativo de software libre y código abierto, una distribución de Linux basada en Debian. Actualmente corre en computadores de escritorio y servidores. Además, está orientado al usuario promedio, con un fuerte enfoque en la facilidad de uso y 
en mejorar la experiencia del usuario.\\

\begin{figure}[!h]
   \centering
   \includegraphics[width=0.3\textwidth]{logo-ubuntu.png}\\
      \caption{\label{fig: Logo ubuntu} Logo ubuntu}
\end{figure}

Ubuntu incluye lo mejor en traducción e infraestructura de accesibilidad que la comunidad de Software Libre tiene para ofrecer, para que Ubuntu pueda ser utilizado por la mayor cantidad de personas posible. Dicho sistema es gratuito, no hay una tarifa adicional 
para la "edición empresarial", ya que está totalmente comrometido con los principios de desarrollo de código abierto; alentan a las personas a usar software de código abierto, mejorarlo y transmitirlo. \\

\subsection{Bash}

Es un lenguaje de comandos y shell de Unix, te permite programar sentencias que causan acciones. En este caso lee y ejecuta comandos desde un archivo, llamado script. Cuando se inicia Bash, ejecuta los comandos en una variedad de archivos de puntos, es similar a los 
comandos de script de shell Bash, que tienen permiso de ejecución habilitado y una directiva de intérprete como cabecera \textbf{$\#$!/bin/bash}. \\

\begin{figure}[!h]
   \centering
   \includegraphics[width=0.3\textwidth]{logo-bash.png}\\
      \caption{\label{fig: Logo bash} Logo bash}
\end{figure}

\subsection{Nano}
Nano es un editor de texto para sistemas Unix basado en curses, que es una biblioteca para el control de terminales sobre sistemas de tipo Unix, posibilitando la construcción de una interfaz para el usuario, para aplicaciones ejecutadas en un terminal. Esta escrito en C y es un clon de Pico, 
el editor del cliente de correo electrónico Pine. Nano trata de emular la funcionalidad y la interfaz de fácil manejo de Pico, pero sin la integración con Pine. \\

\begin{figure}[!h]
   \centering
   \includegraphics[width=0.3\textwidth]{logo-nano.png}\\
      \caption{\label{fig: Logo nano} Logo nano}
\end{figure}

\subsection{Git}
Git es un software de control de versiones, pensando en la eficiencia y la confiabilidad del mantenimiento de versiones de aplicaciones cuando éstas tienen un gran número de archivos de código fuente. Permite que varias personas puedan trabajar en el mismo proyecto sin pisarse los unos en los otros, 
además del control que te aporta sobre tu código, es capaz de volver a versiones anteriores del código. \\

\begin{figure}[!h]
   \centering
   \includegraphics[width=0.3\textwidth]{logo-git.png}\\
      \caption{\label{fig: Logo git} Logo git}
\end{figure}

La comunidad utiliza con frecuencia git, hay varias variantes como gitlab o github que trabajan internamente con git, en este caso se ha utilizado github para el proceso de construcción del código.\\

\begin{figure}[!h]
   \centering
   \includegraphics[width=1.1\textwidth]{Grafica-github-TFG}\\
      \caption{\label{fig: Gráfica github} Gráfica del desarrollo del trabajo en github}
\end{figure}

\subsection{Visual Studio Code}
Visual Studio Code es un editor de código fuente desarrollado por Microsoft para Windows, Linux y macOS. Incluye soporte para la depuración, control integrado de Git, resaltado de sintaxis, finalización inteligente de código, fragmentos y refactorización de código. También es personalizable, 
por lo que los usuarios pueden cambiar el tema del editor, los atajos de teclado y las preferencias. Es gratuito y de código abierto, aunque la descarga oficial está bajo software privativo e incluye características personalizadas por Microsoft. Visual Studio Code se basa en 
Electron, un framework que se utiliza para implementar Chromium y Node.js como aplicaciones para escritorio, que se ejecuta en el motor de diseño Blink. \\

\begin{figure}[!h]
   \centering
   \includegraphics[width=0.8\textwidth]{Ejemplo-Visual-Studio-Code}\\
      \caption{\label{fig: Ejemplo Visual Studio Code} Ejemplo Visual Studio Code}
\end{figure}

Se ha utilizado este editor de texto para realizar la documentación por su fácil manejo y por todas las ayudas que aporta. \\

\subsection{LaTeX}
LaTeX es un sistema de composición de textos, orientado a la creación de documentos escritos que presenten una alta calidad tipográfica. Por sus características y posibilidades, 
es usado de forma especialmente intensa en la generación de artículos, libros científicos que incluyen, entre otros elementos, expresiones matemáticas, artículos académicos, tesis y 
libros técnicos, dado que la calidad tipográfica de los documentos realizados en LaTeX, se considera adecuada a las necesidades de una editorial científica de primera línea, muchas de 
las cuales ya lo emplean. \\

\begin{figure}[!h]
   \centering
   \includegraphics[width=0.8\textwidth]{Ejemplo-LaTeX}\\
      \caption{\label{fig: Ejemplo LaTeX} Ejemplo LaTeX}
\end{figure}

\chapter{Desarrollo del trabajo}
Para empezar, es necesario tener claro la aspiración del trabajo, saber la salud de los sistemas, es por ello por lo que necesitamos 
obtener las métricas de los sistemas. Para ello se ha desarrollado un script en bash capaz de obtener métricas de todo tipo: cpu, 
RAM, disco, etc e introducirlas en un archivo JSON.\\

\begin{figure}[!h]
   \centering
   \includegraphics[width=0.8\textwidth]{MetricasJSON}\\
      \caption{\label{fig: json} Métricas JSON}
\end{figure}

A continuación se mostrarán todas las métricas recogidas detalladamente.\\

\section{Estándares de métricas}

\hyp{} Memoria: kilobyte unidad utilizada para todas las métricas.

\hyp{} Tiempo: milisegundos(preguntar por mbps).

\hyp{} Temperatura: grados celcius.

% https://www.overleaf.com/learn/latex/Paragraphs_and_new_lines
% dsi.uclm.es/personal/AntonioBueno/ESI/monitor%20en%20linux.pdf
\subsection{cpusNumber}
Recogeremos el número de cpus tanto en uso como totales y así poder hacer un seguimiento al rendimiento, obtendremos los elementos con 
los comandos nproc y lscpu. La métrica va a estar nombrada como cpusNumber y va a estar constituida por:\\

Nombre de la métrica: \textbf{cpusNumber}

\hyp{} cpusTotalNumber: número de cpus totales.(int)

\hyp{} cpusUsageNumber: número de cpus en uso. (int)

\subsection{cpu}
Recogeremos los porcentajes de uso de la cpu, lo obtendremos con el comando "iostat -c" (que hay que instalarse). 
La métrica va a estar nombrada como cpu y va a estar constituida por:\\

Nombre de la métrica: \textbf{cpu}

\hyp{} userPercentage: porcentaje de uso de cpu que se produjo durante la ejecución a nivel de usuario. (float)

\hyp{} nicePercentage: porcentaje de uso de cpu que se produjo al ejecutar a nivel de usuario con buena prioridad. (float)

\hyp{} systemPercentage: porcentaje de uso de cpu que se produjo durante la ejecución a nivel de sistema. (float) 

\hyp{} iowaitPercentage: porcentaje de tiempo que la CPU o las CPUs estuvieron inactivas durante las cuales el sistema tuvo una solicitud I/O de disco pendiente. (float)

\hyp{} stealPercentage: porcentaje de tiempo que la CPU virtual o las CPUs pasaron en espera involuntaria mientras el hipervisor daba servicio a otro procesador virtual. (float)

\hyp{} idlePercentage: porcentaje de tiempo que la CPU o las CPU estuvieron inactivas y el sistema no tenía una solicitud de I/O de disco pendiente. (float)

\subsection{mem}
La memoria RAM la obtenemos del comando free, nos centraremos tanto en la memoria RAM
como la memoria swap. La métrica va a estar nombrada como mem y va a estar constituida por:\\

Nombre de la métrica: \textbf{mem}

\hyp{} totalMem: memoria física total.(int)

\hyp{} usedMem: memoria física en uso. (int)

\hyp{} freeMem: memoria física libre. (int)

\hyp{} sharedMem: memoria RAM compartida actualmente en uso. (int)

\hyp{} buffersMem: memoria actual del búffer de caché. (int)

\hyp{} cachedMem: memoria de la caché de disco. (int)

\hyp{} swapTotalMem: memoria virtual total. (int)

\hyp{} swapUsedMem: memoria virtual en uso. (int)

\hyp{} swapFreeMem: memoria virtual libre. (int)

\hyp{} totalRAM: memoria RAM total.(int)

\hyp{} usedRAM: memoria RAM en uso. (int)

\hyp{} freeRAM: memoria RAM libre. (int)

\subsection{disk}
La memoria del disco la obtenemos del comando df \hyp{}\hyp{}total, nos centraremos en el cálculo total y dejamos a un lado el resto 
sistema de ficheros, en un futuro se podría añadir el desglose del cálculo total. La métrica va a estar nombrada disk
y va a estar constituida por:\\
 
Nombre de la métrica: \textbf{disk}

\hyp{} identificatorName: nombre de identificación del disco. (string)
 
\hyp{} totalDisk: memoria total del disco. (int)
 
\hyp{} usedDisk: memoria en uso del disco. (int)
 
\hyp{} freeDisk: memoria libre en el disco. (int)
 
\hyp{} usagePercentDisk: porcentaje de uso del disco. (int)

\subsection{temperature}
La temperatura del sistema está mockeada, está seteada a 27 grados más un random de 0 a 11 grados 
La métrica va a estar nombrada como temperature y va a estar constituida por:\\
  
Nombre de la métrica: \textbf{temperature}
 
\hyp{} degrees: temperatura del pc. (int)

\subsection{partitions}
Las particiones las obtenemos con el comando df memoria del disco la obtenemos del comando df, nos centraremos en la carpeta raíz utilizando 
el elemento /dev/sda1 para filtrar con grep. La métrica va a estar nombrada como partitions y va a estar constituida por:\\
   
Nombre de la métrica: \textbf{partitions}
  
\hyp{} identificatorName: nombre de identificación de la partición. (string)

\hyp{} type: tipo de partición. (string)
  
\hyp{} totalDisk: memoria total de la partición. (int)
  
\hyp{} usedDisk: memoria en uso de la partición. (int)
  
\hyp{} freeDisk: memoria libre de la partición. (int)
  
\hyp{} usagePercentDisk: porcentaje de uso del disco. (int)
   
\hyp{} mountPoint: localización del direcotorio de la partición. (string)

\subsection{ioRatio}
El ratio de IO del disco lo obtendremos a partir del comando iostat, de donde filtraremos la salida para quedarnos con el disco principal sda.
La métrica va a estar nombrada como ioRatio y va a estar constituida por:\\
 
Nombre de la métrica: \textbf{ioRatio}

\hyp{} deviceName: nombre de la partición de memoria. (string)

\hyp{} transfersPerSecond: indica el número de transferencias por segundo que se emitieron al dispositivo. 
Una transferencia es una solicitud I/0 al dispositivo, se pueden combinar varias solicitudes lógicas en una sola solicitud 
porque es de tamaño indeterminado. (float)

\hyp{} kilobytesReadsPerSecond: el número de kilobytes leídos del dispositivo por segundo. (float)

\hyp{} kilobytesWrittenPerSecond: el número de kilobytes escritos en el dispositivo por segundo. (float)

\hyp{} kilobytesRead: El número total de kilobytes leídos. (int)

\hyp{} kilobytesWritten: El número total de kilobytes escritos. (int)

\subsection{logs}
Los logs del sistema los leeremos de archivo /var/log/syslog en nuestro sistema ubuntu.
La métrica va a estar nombrada logs y va a estar constituida por:\\

Nombre de la métrica: \textbf{logs}

\hyp{} date: fecha en la que se hizo el log. (datetime)

\hyp{} nameHost: nombre del sistema. (string)

\hyp{} process?: nombre del proceso del sitema??. (string)?

\hyp{} message: mensaje del log. (string)

\subsection{processesNumber}
Número de procesos del sistema, lo obtendremos con el comando ps, el argumento -a nos devuelve solo los 
procesos activos, nos guardaremos el número de procesos activos y el número de procesos totales
La métrica va a estar nombrada como processesNumber y va a estar constituida por:\\
 
Nombre de la métrica: \textbf{processesNumber}
 
\hyp{} activeProcessesNumber: el número de procesos activos de la máquina. (int)
 
\hyp{} totalProcessesNumber: el número total de procesos de la máquina. (int)

\subsection{process}
La tabla de procesos del sistema la obtendremos del comando ps, filtramos el comando para que nos devuelva 
las entradas que nos interesan, que son las que tienen carga de cpu, es decir aquellas que tengan distinto de 0 el porcentaje de cpu.
La métrica va a estar nombrada como process y va a estar constituida por:\\
  
Nombre de la métrica: \textbf{process}
  
\hyp{} usedPercentageCpu: porcentaje de uso de la cpu del proceso. (float)

\hyp{} pid: número identificador del proceso. (int)
  
\hyp{} usedPercentageMem: porcentaje de uso de la memoria RAM del proceso. (float)
  
\hyp{} nice: número que define la prioridad del proceso. Esta prioridad se llama Niceness en Linux, 
y tiene un valor entre -20 y 19. Cuanto más bajo sea el índice de Niceness, mayor será una prioridad dada a esa tarea.
El valor predeterminado de todos los procesos es 0. (int)

\hyp{} group: nombre del grupo al que pertenece el proceso. (string)

\hyp{} user: nombre del usuario que ejecutó el proceso. (string)

\hyp{} state: estado en el que se encuentra el proceso (R en ejecución, S dormido, T detenido, X muerto). (string)

\hyp{} start: hora a la que empezó el proceso. (datetime)
  
\hyp{} cpuTime: tiempo de ejecución en cpu. (datetime)
  
\hyp{} command: descripción de la ejecución del proceso. (string)


\subsection{latency}
La latencia es el tiempo que lleva enviar una señal más el tiempo que lleva recibir un acuse de recibo de esa señal.
Para calcularla utilizamos el comando ping en localhost con 3 paquetes y nos quedamos con el rtt. 
La métrica va a estar nombrada como latency y va a estar constituida por:\\
  
Nombre de la métrica: \textbf{latency}

\hyp{} minRTT: es el número mínimo que tardó una  de las peticiones ECHO\_ REQUEST. (float)

\hyp{} meanRTT: es la media de lo que tardaron las peticiones ECHO\_REQUEST. (float)

\hyp{} maxRTT: es el número máximo que tardó una de las peticiones ECHO\_REQUEST. (float)

\hyp{} mdevRTT: es la desviación estándar, esencialmente un promedio de cuán lejos está cada RTT de ping de la RTT media. 
Cuanto más alto es el número, más variable es el RTT. (float)

\hyp{} packageTransmited: es el número de paquetes transmitidos durante la prueba de latencia. (int)

\hyp{} packageReceived: es el número de paquetes recibidos durante la prueba de latencia. (int)

\hyp{} packageLossPercentage: es el porcentage de paquetes perdidos durante la prueba de latencia. (float)

\hyp{} timeRequest: son los milisegundos que se han tardado en hacer la prueba de latencia. (int)

\hyp{} clientServer: son los milisegundos que ha tardado el servidor en recibir las métricas. (int) 

\subsection{networkMetrics}
Las métricas de red que disponen las tarjetas de red del sistema las obtendremos con el comando ifconfig.
La métrica va a estar nombrada como netWorkMetrics y va a estar constituida por:\\
  
Nombre de la métrica: \textbf{networkMetrics}

\hyp{} networkCardName: nombre de la tarjeta de red. (string)

\hyp{} MTU: (unidad de transmisión máxima) es el tamaño de cada paquete recibido por la tarjeta de red. El valor de MTU para todos 
los dispositivos Ethernet de manera predeterminada se establece en 1500. Establecer un valor más alto podría poner en peligro 
la fragmentación del paquete o desbordamientos del búfer. (int)

\hyp{} IP: ip visible de la tarjeta de red. (string)

\hyp{} netMask: la máscara de red del sistema. (string)

\hyp{} broadcastAddress: la dirección que se usará para representar las transmisiones a la red. (string)

\hyp{} IPv6Address: es la etiqueta numérica usada para identificar la interfaz de red en una red IPv6. (string)

\hyp{} MACAddress: es la dirección MAC de la tarjeta de red. (string)

\hyp{} txQueueLen: denota la longitud de la cola de transmisión del dispositivo. Por lo general, lo configura en valores más pequeños 
para dispositivos más lentos con una latencia alta. (int)

\hyp{} connectionProtocol: protocolo de conexión utilizado. (string)

\hyp{} RXPackages: número de paquetes recibidos por la interfaz de red. (int)

\hyp{} RXErrors: número de paquetes con error recibidos por la interfaz de red. (int)

\hyp{} TXPackages: número de paquetes transmitidos por la interfaz de red. (int)

\hyp{} TXErrors: número de paquetes con error transmitidos por la interfaz de red. (int)

\hyp{} collisions: el valor de este campo debería ser idealmente 0. Si tiene un valor mayor que 0, podría significar que los paquetes
están colisionando mientras atraviesan la red, una señal segura de congestión de la red. (int)

\subsection{systemAdditionalInfo}
La información adicional del sistema la obtendremos del comando uptime.
La métrica va a estar nombrada como systemAdditionalInfo y va a estar constituida por:\\
  
Nombre de la métrica: \textbf{systemAdditionalInfo}

\hyp{} systemRunningTime: es el tiempo que lleva funcionando el sistema. (string)

\hyp{} usersLoggedOnNumber: número de usuarios conectados. (int)

\hyp{} systemLoadAverage1M: promedio de carga del sistema durante el último minuto. (float)

\hyp{} systemLoadAverage5M: promedio de carga del sistema durante los últimos 5 minutos. (float)

\hyp{} systemLoadAverage15M: promedio de carga del sistema durante los últimos 15 minutos. (float)

Una vez obtenidas las métricas, hay que almacenarlas en una base de datos. Para ello, hay que plantearse el cómo hacerlo, ¿qué forma 
sería la más eficiente? ¿quá cada sistema se pueda conectar a la base de datos para almacenarlas o solo una entidad es la encargada 
de introducirlas?. Por seguridad y por acoplamiento es mejor que solo una entidad sea capaz de almacenar las métricas, independientemente 
del tipo de sistema que sea.\\

Por lo tanto, es necesario desarrollar un sistema cliente-servidor, donde el servidor se encargué de almacenar las métricas de los sistemas 
y el cliente recogerlas y mandarlas. Indirectamente estos tipos de sistemas te obligan a gestionar las comunicaciones entre ellos, así que es necesario 
hacer un protocolo de comunicaciones para que se entiendan en todo momento el servidor y los clientes.\\

\section{Servidor}

El servidor está desarrollado en python, en la versión 3.7. En primer lugar, el servidor se encarga de setear su propia configuración según un json 
que permite actualizar la dirección IP, el puerto o el tamaño del buffer para el control de las comunicaciones, también te permite controlar que sistemas puden 
comunicarse con el servidor, un plus de seguridad que solo deja conectarse con máquinas ya conocidas, además setea la contraseña por la cuál se conectan los clientes 
al servidor y por el último los formatos elegidos para el sistema de logs que dispone el servidor, el sistema de logs es simplemente para tener un control de errores, 
en el caso de que algo falle en el sistema quedará reflejado en un archivo aparte llamado SystemMetrics-Server.log.\\


\begin{figure}[!h]
   \centering
   \includegraphics[width=0.8\textwidth]{Server-configuration}\\
      \caption{\label{fig: Server configuration} Server configuration}
\end{figure}

Dicho servidor siempre está funcionando, en el momento que haya sido ejecutado entrará en un bucle de donde no podrá salir hasta que un usuario pare la ejecución. 
En primer lugar prepara el socket por el cuál permitirá la comunicación y una vez hecho eso entra en un bucle infinito con el siguiente algoritmo; aceptamos una comunicación 
entrante (a través de una línea bloqueante que nos la da la líbrería "socket") y se la derivamos a un thread, con esto permitimos que haya concurrencia y en el caso de que 
otro cliente quiera comunicarse con el servidor podrá dicho servidor lanzar otro thread para que se comuniquen. Además cada conexión entrante tiene un timeout, es decir solo podrán 
comunicarse por un período de tiempo, en este caso 120 segundos. \\

El servidor dispone de 3 funcionalidades; que solo la utilizan los threads. Cuando un thread es creado se pone a la escucha de nuevos mensajes, en donde solo hay 3 posibles mensajes: un mensaje 
de respuesta que da el servidor para avisar a los clientes de que la primera comunicación a ido bien, un segundo mensaje que contiene las métricas, por lo tanto cada thread trata dichas métricas 
y las almacena en una base de datos de series de tiempo llamada InfluxDB y por último un mensaje para cercionarse de que se cierran las conexiones con los clientes. Siempre ocurre el mismo algoritmo, 
el cliente en primera instancia se dispone a comunicarse con el servidor, le manda un mensaje con la contraseña anteriormente vista y si coincide el servidor le manda un respuesta de que todo ha ido 
bien, el cliente al recibir dicho mensaje le manda las métricas al servidor, una vez recibidas el servidor las parsea y las almacena en InfluxDB con un timestamp, por último si todo ha ido correctamente 
el cliente le manda un mensaje al servidor pàra cerrar la comunicación. \\ 


\section{Cliente}
El cliente sigue la misma estructura del servidor está escrito en python en la versión 3.7, se inicia y se setea su propia configuración. Dispone de un JSON donde lee en que ip se encuentra el servidor, la ip propia donde poder comunicarse, el puerto, 
el tamaño del buffer, la contraseña para interactuar con el servidor, los formatos elegidos para el sistema de logs y a diferencia de la configuración del servidor éste dispone de dos parámetros más: que tipo 
de sistema es(debian, windows, ubuntu, etc) y que tipo de métricas enviará, estos últimos parámetros son para llevar un control de que sistema es cada uno para que en un futuro si quisiéramos filtrar por los sistemas 
de un solo tipo pudiésemos. \\

\begin{figure}[!h]
   \centering
   \includegraphics[width=0.8\textwidth]{Client-configuration}\\
      \caption{\label{fig: Client configuration} Client configuration}
\end{figure}

Una vez el cliente se ha seteado, se prepara para empezar la comunicación con el servidor. En primer lugar, le manda un mensaje con la contraseña y se pone a la espera de la respuesta del servidor, si todo ha ido bien 
ejecuta un script en bash que calcula las métricas del sistema y las introduce en un JSON, una vez generado el JSON lee las métricas del archivo y crea el mensaje con ellas para mandarlas al servidor. Por último, corta la comunicación 
con el servidor para que la próxima vez que vaya a mandar métricas empiece el algoritmo desde cero. \\
\section{Protocolo de comunicaciones}

Para entender el protocolo de comunicaciones, hay que entender protobuffer, una herramienta que permite programar los mensajes tal y como quieras. Protobuffer te permite setear atributos en las cabeceras, que él por detrás se encarga de 
comprimirlos y generar una estructura de datos serializada, por lo tanto una vez llegue el mensaje a su destino solo habría que deserializarlo para obtener cada métrica. \\

La versión utilizada es proto3, que a diferencia de proto2 cambia la sintaxis y los campos siempre son opcionales a la hora de generar la estructura del mensaje, no permite poner campos requeridos, Google decidió eliminarlo para 
evitar posibles fallos. Ante ello solo queda el control por parte de la aplicación, es decir, cuando se mande un mensaje se asegure de que ciertos campos hayan sido rellenados previamente. \\


\begin{figure}[!h]
   \centering
   \includegraphics[width=0.8\textwidth]{ProtocolBuffer-version}\\
      \caption{\label{fig: ProtocolBuffer version} ProtocolBuffer version}
\end{figure}

La estructura principal del mensaje se compone de 4 estructuras de mensajes distintos, de donde solo 1 es obligatoria, la configuración. \\

\begin{figure}[!h]
   \centering
   \includegraphics[width=0.6\textwidth]{Estructura-mensaje}\\
      \caption{\label{fig: Estructura mensaje} Estructura mensaje}
\end{figure}

Dicha configuración define que tipo de mensaje será, a través de una enumeración que mostrará si es un ACK, si es un mensaje para cerrar la comunicación, en caso contrario para crearla o un mensaje con las métricas del sistema . \\

El mensaje de tipo ``Config'', dispone del hostname de quién manda el mensaje, la ip y el puerto por el cuál se comunican. La enumeración ``Message type'' identifica que tipo de mensaje es, por lo tanto aunque no ponga 
que sean campos requeridos es necesario rellenarlo siempre que se manden mensajes entre sistemas. \\

\begin{figure}[!h]
   \centering
   \includegraphics[width=0.5\textwidth]{Mensaje-config}\\
      \caption{\label{fig: Configuración obligatoria del mensaje} Configuración obligatoria del mensaje}
\end{figure}

En la figura 5.5 se aprecian 3 tipos de mensajes a parte del mensaje de configuración obligatorio, dejando para el final el mensaje de tipo ``SystemMetric'', se proseguirá explicar los tipos de mensajes ``ACK'' y ``StartCommunication''. 
Ambos tipos de mensajes solo disponen de un string como se ve en la figura 5.7, en el caso de ``StartCommunication'' la contraseña por la cuál va a permitir empezar la interacción con el servidor y en el caso de ``ACK'' el mensaje 
de vuelta que ejecuta el servidor. \\

\begin{figure}[!h]
   \centering
   \includegraphics[width=0.5\textwidth]{Tipos-basicos-de-mensaje}\\
      \caption{\label{fig: Tipos básicos de mensaje} Tipos básicos de mensaje}
\end{figure}

Por último, la estructura de mensaje que dispone de las métricas, llamada ``SystemMetric'' que se puede observar en la figura 5.8. Esta estructura de mensaje dispone de un string que define el tipo de métricas que recibe: ubuntu, raspbian y 
en el caso de que se inserten nuevos sistemas el tipo que las define; por otro lado un timestamp de la hora a la que se mandó el mensaje, dicho timestamp es obligatorio con el trato de InfluxDB, la base de datos de series temporales y finalmente todas las 
métricas que se recogen de los clientes, dichas métricas están definidas y detalladas en el apartado 5.1 ``Estándares de métricas''. En el caso de que una métrica no se pueda recoger, se seteará al valor 0 por defecto.\\

\begin{figure}[!h]
   \centering
   \includegraphics[width=0.5\textwidth]{Estructura-SystemMetrics}\\
      \caption{\label{fig: Estructura SystemMetrics} Estructura SystemMetrics}
\end{figure}

\chapter{Bibliografía}
https://pandorafms.com/blog/es/monitorizacion-de-sistemas/ \\
https://www.docker.com/resources/what-container \\
https://developers.google.com/protocol-buffers \\
https://medium.com/jmtorres/protocol-buffers-f5b266783652 \\
https://grafana.com/oss/grafana/ \\
https://en.wikipedia.org/wiki/InfluxDB \\
https://www.influxdata.com/ \\
https://www.jetbrains.com/es-es/pycharm/ \\
https://help.ubuntu.com/lts/installation-guide/s390x/ch01s01.html \\
http://metodos.fam.cie.uva.es/~latex/apuntes/apuntes3.pdf \\
https://docs.latexbase.com/symbols \\
https://www.comoinstalarlinux.com/como-usar-el-editor-nano-linux/\\
https://es.wikipedia.org/wiki/Curses \\
https://git-scm.com/ \\
https://code.visualstudio.com/ \\
https://es.wikipedia.org/wiki/LaTeX \\

\chapter{Anexo}
\listoffigures
\end{document}